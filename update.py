import requests
import json
import re
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==========================================
# 1. Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¹Ù…Ù„Ø§Ù‚Ø© (Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹Ø§Øª Ø§Ù„Ø°ÙƒÙŠØ©)
# ==========================================
URLS = [
    # Ù‚ÙˆØ§Ø¦Ù… Ø±Ø³Ù…ÙŠØ© (Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¬ÙˆØ¯Ø©)
    "https://iptv-org.github.io/iptv/countries/jo.m3u",
    "https://iptv-org.github.io/iptv/countries/eg.m3u",
    "https://iptv-org.github.io/iptv/countries/sa.m3u",
    "https://iptv-org.github.io/iptv/countries/ae.m3u",
    
    # Ù‚ÙˆØ§Ø¦Ù… Ø¶Ø®Ù…Ø© Ø¬Ø¯Ø§Ù‹ (Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Xtream Ùˆ Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø´ÙØ±Ø© Ø§Ù„Ù…ÙØªÙˆØ­Ø©)
    "https://iptv-org.github.io/iptv/languages/ara.m3u",
    "https://raw.githubusercontent.com/Free-TV/IPTV/master/playlist.m3u8",
    
    # Ù‚ÙˆØ§Ø¦Ù… Ø¹Ø§Ù„Ù…ÙŠØ© (Ø³Ù†Ø¨Ø­Ø« Ø¨Ø¯Ø§Ø®Ù„Ù‡Ø§ Ø¹Ù† Ù‚Ù†ÙˆØ§Øª Ù…Ø­Ø¯Ø¯Ø©)
    "https://iptv-org.github.io/iptv/categories/documentary.m3u",
    "https://iptv-org.github.io/iptv/categories/kids.m3u",
    "https://iptv-org.github.io/iptv/categories/sports.m3u"
]

# Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙŠ Ù†Ø±ÙŠØ¯ "ØµÙŠØ¯Ù‡Ø§" Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©
TARGETS = [
    "mbc", "bein", "osn", "rotana", "art ", "shahid", "alkass", "ssc",
    "national geo", "nat geo", "discovery", "animal planet",
    "spacetoon", "cartoon network", "cn arabia", "nickelodeon",
    "jordan", "roya", "mamlaka", "jazeera", "alarabiya"
]

# ==========================================
# 2. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙØ­Øµ (Ø§Ù„Ù…Ø­Ø±Ùƒ)
# ==========================================
MAX_WORKERS = 30  # Ø¹Ø¯Ø¯ Ø§Ù„Ø±ÙˆØ¨ÙˆØªØ§Øª Ø§Ù„ØµØºÙŠØ±Ø© Ø§Ù„ØªÙŠ ØªÙØ­Øµ ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª (Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø³Ø±Ø¹Ø©)
TIMEOUT = 4       # Ù…Ø¯Ø© Ø§Ù„ØµØ¨Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø§Ø¨Ø· Ù‚Ø¨Ù„ Ø§Ø¹ØªØ¨Ø§Ø±Ù‡ Ù…ÙŠØªØ§Ù‹ (Ø«ÙˆØ§Ù†ÙŠ)

# ØªÙ…ÙˆÙŠÙ‡ Ø§Ù„Ø·Ù„Ø¨ (ÙˆÙƒØ£Ù†Ù‡ Ù…ØªØµÙØ­ Ø­Ù‚ÙŠÙ‚ÙŠ)
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

# ==========================================
# 3. Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø°ÙƒÙŠØ©
# ==========================================

def check_stream(url):
    """ÙˆØ¸ÙŠÙØ© ÙØ­Øµ Ø§Ù„Ø±Ø§Ø¨Ø·: Ù‡Ù„ ÙŠØ¹Ù…Ù„ Ø£Ù… Ù„Ø§ØŸ"""
    try:
        # Ø·Ù„Ø¨ Ø®ÙÙŠÙ (Stream) Ø¯ÙˆÙ† ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙƒØ§Ù…Ù„Ø§Ù‹
        with requests.get(url, headers=HEADERS, stream=True, timeout=TIMEOUT) as r:
            # Ù†Ù‚Ø¨Ù„ Ø§Ù„Ø±Ø§Ø¨Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙƒÙˆØ¯ 200 (OK) ÙˆÙƒØ§Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙÙŠØ¯ÙŠÙˆ
            if r.status_code == 200:
                return True
    except:
        return False
    return False

def clean_name(name):
    """ØªÙ†Ø¸ÙŠÙ ÙˆØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù‚Ù†ÙˆØ§Øª"""
    name = name.lower()
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    for w in ["hd", "sd", "fhd", "4k", "hevc", "ar", "arabic", "tv", "channel", "live", "stream", "+"]:
        name = name.replace(w, "")
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ²
    name = re.sub(r'[^a-z0-9]', '', name)
    
    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø´Ù‡ÙˆØ±Ø©
    if "mbc" in name:
        if "drama" in name: return "mbcdrama"
        if "action" in name: return "mbcaction"
        if "2" in name: return "mbc2"
        if "3" in name: return "mbc3"
        if "4" in name: return "mbc4"
        if "masr" in name: return "mbcmasr"
        if "iraq" in name: return "mbciraq"
        if "booly" in name: return "mbcbollywood"
    
    if "national" in name or "nat" in name: return "natgeo"
    if "jordan" in name: return "jordantv"
    
    return name

def get_cat(name):
    n = name.lower()
    if "sport" in n or "koora" in n or "bein" in n: return "sports"
    if "news" in n or "jazeera" in n or "arabia" in n: return "news"
    if "kid" in n or "cartoon" in n or "spacetoon" in n: return "kids"
    if "movi" in n or "cinema" in n or "film" in n or "rotana" in n or "mbc 2" in n: return "movies"
    if "docu" in n or "geo" in n or "wild" in n or "planet" in n: return "docu"
    return "general"

# ==========================================
# 4. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ==========================================
def update():
    all_candidates = []
    print("ğŸ“¡ Ø¬Ø§Ø±ÙŠ Ø³Ø­Ø¨ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø¶Ø®Ù…Ø© ÙˆØ§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù‚Ù†ÙˆØ§Øª...")

    for url in URLS:
        try:
            resp = requests.get(url, timeout=15)
            resp.encoding = 'utf-8'
            lines = resp.text.split('\n')
            
            meta = {}
            for line in lines:
                line = line.strip()
                if line.startswith("#EXTINF"):
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    name_m = re.search(r'tvg-name="([^"]+)"', line) or re.search(r',(.*)', line)
                    name = name_m.group(1).strip() if name_m else "Unknown"
                    
                    logo_m = re.search(r'tvg-logo="([^"]+)"', line)
                    logo = logo_m.group(1) if logo_m else ""
                    
                    # Ù‡Ù„ Ø§Ù„Ù‚Ù†Ø§Ø© Ø¹Ø±Ø¨ÙŠØ© Ø£Ùˆ Ù…Ù† Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©ØŸ
                    is_arab_source = "ara.m3u" in url or "jo.m3u" in url or "eg.m3u" in url or "sa.m3u" in url
                    is_target = any(t in name.lower() for t in TARGETS)
                    
                    if is_arab_source or is_target:
                        meta = {"name": name, "logo": logo}
                    else:
                        meta = {} # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù‚Ù†ÙˆØ§Øª ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø©
                        
                elif line.startswith("http") and meta:
                    if not line.endswith(".ts"): # Ù†ØªØ¬Ù†Ø¨ Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙ‚Ø·ÙŠØ¹ Ø§Ù„ØµØºÙŠØ±Ø©
                        all_candidates.append({
                            "name": meta['name'],
                            "logo": meta['logo'],
                            "url": line
                        })
                    meta = {}
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ØµØ¯Ø± {url}: {e}")

    print(f"ğŸ“¦ ÙˆØ¬Ø¯Ù†Ø§ {len(all_candidates)} Ø±Ø§Ø¨Ø· Ù…Ø­ØªÙ…Ù„. Ø¨Ø¯Ø¡ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø°ÙƒÙŠ (Ù‡Ø°Ø§ Ø³ÙŠØ£Ø®Ø° ÙˆÙ‚ØªØ§Ù‹)...")

    # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ÙØ±ÙŠØ¯Ø© Ù„Ù„ÙØ­Øµ (Ù„Ø¹Ø¯Ù… ÙØ­Øµ Ù†ÙØ³ Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ø±ØªÙŠÙ†)
    unique_links = set(c['url'] for c in all_candidates)
    working_links = set()

    # --- Ø§Ù„ÙØ­Øµ Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠ (Multi-threading) ---
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_url = {executor.submit(check_stream, url): url for url in unique_links}
        
        checked_count = 0
        for future in as_completed(future_to_url):
            url = future_to_url[future]
            checked_count += 1
            if checked_count % 50 == 0: print(f"â³ ØªÙ… ÙØ­Øµ {checked_count}/{len(unique_links)}...")
            
            try:
                if future.result():
                    working_links.add(url)
            except:
                pass

    print(f"âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ÙØ­Øµ. Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¹Ø§Ù…Ù„Ø© ÙØ¹Ù„ÙŠØ§Ù‹: {len(working_links)}")

    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    final_channels = {}
    
    for item in all_candidates:
        if item['url'] in working_links:
            cid = clean_name(item['name'])
            
            if cid not in final_channels:
                final_channels[cid] = {
                    "name": item['name'],
                    "logo": item['logo'],
                    "category": get_category(item['name']),
                    "urls": []
                }
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ù„Ù‚Ù†Ø§Ø©
            if item['url'] not in final_channels[cid]['urls']:
                final_channels[cid]['urls'].append(item['url'])
                # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù„ÙˆØ¬Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù‚Ø¯ÙŠÙ… ÙØ§Ø±ØºØ§Ù‹
                if not final_channels[cid]['logo'] and item['logo']:
                    final_channels[cid]['logo'] = item['logo']

    # ØªØ­ÙˆÙŠÙ„ Ù„Ù‚Ø§Ø¦Ù…Ø© ÙˆØªØ±ØªÙŠØ¨
    output_list = list(final_channels.values())
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø¨Ø¯ÙˆÙ† Ø±ÙˆØ§Ø¨Ø· (Ø§Ø­ØªÙŠØ§Ø·)
    output_list = [c for c in output_list if c['urls']]

    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª
    priority = ["Jordan", "Roya", "Mamlaka", "MBC", "Jazeera", "BeIN", "Nat Geo"]
    def sort_logic(c):
        n = c['name'].lower()
        for i, p in enumerate(priority):
            if p.lower() in n: return i
        return 100

    output_list.sort(key=sort_logic)

    print(f"ğŸ‰ ØªÙ… Ø­ÙØ¸ {len(output_list)} Ù‚Ù†Ø§Ø© Ù…Ø¤ÙƒØ¯Ø©.")
    
    with open("channels.json", "w", encoding="utf-8") as f:
        json.dump(output_list, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    update()

import requests
import json
import re

# ==========================================
# 1. Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¹Ù…Ù„Ø§Ù‚Ø© (Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹Ø§Øª)
# ==========================================
SOURCES = [
    # Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø£Ø±Ø¯Ù†ÙŠØ© (Ø§Ù„Ø£Ø³Ø§Ø³)
    "https://iptv-org.github.io/iptv/languages/ara.m3u",
    "https://iptv-org.github.io/iptv/countries/jo.m3u",
    
    # Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ÙŠØ© Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© (Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Nat Geo)
    "https://iptv-org.github.io/iptv/categories/documentary.m3u",
    
    # Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø£Ø·ÙØ§Ù„ ÙˆØ§Ù„Ø£ÙÙ„Ø§Ù… Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©
    "https://iptv-org.github.io/iptv/categories/kids.m3u",
    "https://iptv-org.github.io/iptv/categories/movies.m3u",
    "https://iptv-org.github.io/iptv/categories/family.m3u",
    
    # Ù‚ÙˆØ§Ø¦Ù… Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¨Ø« Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© (Samsung TV Plus, Pluto, etc)
    # Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚Ù†ÙˆØ§Øª Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø© ÙˆÙ…Ø¬Ø§Ù†ÙŠØ©
    "https://iptv-org.github.io/iptv/index.m3u" 
]

# ==========================================
# 2. Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ø¨Ø­Ø« (ØµØ§Ø¦Ø¯ Ø§Ù„Ù‚Ù†ÙˆØ§Øª)
# ==========================================
# Ø³Ù†Ø¨Ø­Ø« Ø¹Ù† Ù‡Ø°Ù‡ Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙÙŠ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© Ø­ØªÙ‰ Ù„Ùˆ Ù„Ù… ØªÙƒÙ† Ø¹Ø±Ø¨ÙŠØ©
IMPORTANT_KEYWORDS = [
    "national geographic", "nat geo", "wild", "adventure", # ÙˆØ«Ø§Ø¦Ù‚ÙŠØ§Øª
    "mbc", "shahid", "rotana", "art ",                   # ØªØ±ÙÙŠÙ‡ Ø¹Ø±Ø¨ÙŠ
    "beinsports", "alkass", "ad sports", "ssc",          # Ø±ÙŠØ§Ø¶Ø©
    "samsung", "xumo", "pluto",                          # Ù…Ù†ØµØ§Øª Ø¹Ø§Ù„Ù…ÙŠØ©
    "spacetoon", "cartoon network", "nickelodeon"        # Ø£Ø·ÙØ§Ù„
]

# ==========================================
# 3. Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ©
# ==========================================

def normalize_name(name):
    """ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ù„Ø¯Ù…Ø¬ Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø§Øª"""
    name = name.lower()
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø²ÙˆØ§Ø¦Ø¯ Ù…Ø«Ù„ HD, FHD, 4K, TV
    replacements = ["hd", "sd", "fhd", "4k", "hevc", "ar", "arabic", "tv", "channel", "live"]
    for word in replacements:
        name = name.replace(word, "")
    
    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù…Ø´Ù‡ÙˆØ±Ø©
    if "national geographic" in name: name = "nat geo"
    if "mbc" in name and "drama" in name: name = "mbc drama"
    if "mbc" in name and "action" in name: name = "mbc action"
    if "mbc" in name and "2" in name: name = "mbc 2"
    if "mbc" in name and "3" in name: name = "mbc 3"
    if "mbc" in name and "4" in name: name = "mbc 4"
    if "jordan" in name: name = "jordan tv"
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ²
    name = re.sub(r'[^a-z0-9]', '', name)
    return name

def get_category(name, group):
    """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªØµÙ†ÙŠÙ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³Ù…"""
    text = (name + " " + group).lower()
    
    if "sport" in text or "ball" in text or "koora" in text: return "sports"
    if "news" in text or "arabia" in text or "jazeera" in text: return "news"
    if "kid" in text or "cartoon" in text or "anime" in text or "spacetoon" in text: return "kids"
    if "movi" in text or "cinema" in text or "film" in text or "drama" in text or "rotana" in text: return "movies"
    if "docu" in text or "geo" in text or "wild" in text or "planet" in text: return "docu"
    if "relig" in text or "qura" in text or "sunna" in text: return "religious"
    
    return "general"

def update():
    channels_map = {}
    print("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ø¢Ù„Ø§Ù Ø§Ù„Ù‚Ù†ÙˆØ§Øª...")

    for url in SOURCES:
        try:
            print(f"ğŸ“¡ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø³Ø­: {url} ...")
            # Ù†Ø³ØªØ®Ø¯Ù… timeout Ù‚ØµÙŠØ± Ù„ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø¨Ø·ÙŠØ¦Ø©
            response = requests.get(url, timeout=15)
            response.encoding = 'utf-8'
            lines = response.text.split('\n')
            
            current_info = {}
            
            for line in lines:
                line = line.strip()
                if line.startswith("#EXTINF"):
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    name_match = re.search(r'tvg-name="([^"]+)"', line) or re.search(r',(.*)', line)
                    raw_name = name_match.group(1).strip() if name_match else "Unknown"
                    
                    logo_match = re.search(r'tvg-logo="([^"]+)"', line)
                    logo = logo_match.group(1) if logo_match else ""
                    
                    group_match = re.search(r'group-title="([^"]+)"', line)
                    group = group_match.group(1).lower() if group_match else ""
                    
                    # --- Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ø°ÙƒÙŠ ---
                    # Ù†Ù‚Ø¨Ù„ Ø§Ù„Ù‚Ù†Ø§Ø© ÙÙŠ Ø­Ø§Ù„ØªÙŠÙ†:
                    # 1. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ù‡ÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø¹Ø±Ø¨ÙŠØ© (ara.m3u Ø£Ùˆ jo.m3u)
                    # 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¹Ø§Ù„Ù…ÙŠØ©ØŒ ÙˆÙ„ÙƒÙ† Ø§Ø³Ù… Ø§Ù„Ù‚Ù†Ø§Ø© ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø© Ù…Ù‡Ù…Ø© (Ù…Ø«Ù„ Nat Geo)
                    
                    is_target = False
                    
                    if "ara.m3u" in url or "jo.m3u" in url:
                        is_target = True
                    else:
                        # Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© Ø¹Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
                        for keyword in IMPORTANT_KEYWORDS:
                            if keyword in raw_name.lower():
                                is_target = True
                                break
                    
                    if is_target:
                        current_info = {
                            "name": raw_name,
                            "logo": logo,
                            "group": group
                        }
                    else:
                        current_info = {} # ØªØ¬Ø§Ù‡Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ù†Ø§Ø©
                        
                elif line.startswith("http") and current_info:
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ù…Ù‚Ø¨ÙˆÙ„Ø©
                    clean_id = normalize_name(current_info['name'])
                    
                    if clean_id not in channels_map:
                        # Ù‚Ù†Ø§Ø© Ø¬Ø¯ÙŠØ¯Ø©
                        cat = get_category(current_info['name'], current_info['group'])
                        
                        # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³Ù… Ù„Ù„Ø¹Ø±Ø¶ (Capitalize)
                        display_name = current_info['name']
                        if "mbc" in clean_id: display_name = display_name.upper()
                        
                        channels_map[clean_id] = {
                            "name": display_name,
                            "logo": current_info['logo'],
                            "category": cat,
                            "urls": []
                        }
                    
                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø±Ø§Ø¨Ø· (Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙƒØ±Ø±Ø§Ù‹)
                    if line not in channels_map[clean_id]['urls']:
                        channels_map[clean_id]['urls'].append(line)
                        
                    current_info = {}

        except Exception as e:
            print(f"âš ï¸ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù…ØµØ¯Ø± {url} Ø¨Ø³Ø¨Ø¨ Ø®Ø·Ø£: {e}")

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ù„Ù‚Ø§Ø¦Ù…Ø©
    final_list = list(channels_map.values())
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙŠ Ù„ÙŠØ³ Ù„Ù‡Ø§ Ø±ÙˆØ§Ø¨Ø·
    final_list = [ch for ch in final_list if len(ch['urls']) > 0]
    
    # --- ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª Ù„Ù„Ø¹Ø±Ø¶ ---
    # Ù†Ø±ÙŠØ¯ Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ© ÙˆØ§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙƒØ¨Ø±Ù‰ ÙÙŠ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©
    priority_words = ["Jordan", "Roya", "Mamlaka", "Jazeera", "MBC", "BeIN", "National Geo", "Rotana"]
    
    def sort_score(ch):
        name = ch['name'].lower()
        for index, word in enumerate(priority_words):
            if word.lower() in name:
                return index # ÙƒÙ„Ù…Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ù‚Ù… Ø£Ù‚Ù„ØŒ Ø¸Ù‡Ø±Øª Ø£ÙˆÙ„Ø§Ù‹
        return 100 # Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ ØªØ£ØªÙŠ Ù„Ø§Ø­Ù‚Ø§Ù‹
        
    final_list.sort(key=sort_score)

    print(f"âœ… ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡! ØªÙ… ØªØ¬Ù…ÙŠØ¹ {len(final_list)} Ù‚Ù†Ø§Ø©ØŒ ÙˆØªÙ… Ø¯Ù…Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø©.")

    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
    with open("channels.json", "w", encoding="utf-8") as f:
        json.dump(final_list, f, ensure_ascii=False, indent=2)
        
    return final_list

if __name__ == "__main__":
    update()
